---
layout: page
title: Research
tags: [research, umang, bhatt, cmu, cambridge, explainability, machine learning, ML, interpretability, artificial intelligence, AI, graduate, human-machine team, human-AI, collaboration, responsible AI, nyu, professor]
modified: 2014-08-08T20:53:07.573882-04:00
comments: false
---

My interests broadly lie in the field of **trustworthy machine learning** (ML). During my PhD, I focused on algorithmic transparency and its effects on AI-assisted decision-making. I am currently build tools for routing decision-makers to appropriate forms of decision support and for cataloging how AI systems are used in decision-making contexts all over the world. 

You can find the most up-to-date list of my work on [Google Scholar](https://scholar.google.com/citations?user=qq8bxPkAAAAJ&hl=en). The list below is updated periodically. 

### Journal and Conference Publications (Refereed and Archived) 

1. Katherine Collins\*, Ilia Sucholutsky\*, **Umang Bhatt**\*, Kartik Chandra\*, Lionel Wong\*, Mina Lee, Cedegao Zhang, Tan Zhi-Xuan, Mark Ho, Vikash Mansinghka, Adrian Weller, Joshua Tenenbaum, Thomas Griffths      
<span style="color:SlateBlue">Building Machines that Learn and Think with People</span>      
*Nature Human Behavior, 2024.*      
[<button type="button" class="btn btn-info">Paper</button>](https://www.nature.com/articles/s41562-024-01991-9)    

1. **Umang Bhatt**\*, Holli Sargeant\*      
<span style="color:SlateBlue">When Should Algorithms Resign? A Proposal for AI Governance</span>      
*IEEE Computer, 2024.*      
[<button type="button" class="btn btn-info">Paper</button>](https://ieeexplore.ieee.org/document/10687308)  

1. Katherine Collins, Albert Jiang, Simon Frieder, Lionel Wong, Miri Zilka, **Umang Bhatt**, Thomas Lukasiewicz, Yuhuai Wu, Joshua Tenenbaum, William Hart, Timothy Gowers, Wenda Li, Adrian Weller, Mateja Jamnik      
<span style="color:SlateBlue">Evaluating Language Models for Mathematics through Interactionse</span>      
*Proceedings of the National Academy of Sciences, 2024.*      
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2408.03943)
[<button type="button" class="btn btn-danger">Code</button>](https://github.com/barkermrl/feedback-log)   

1. Sreejan Kumar, Raja Marjieh, Byron Zhang, Declan Campbell, Michael Hu, **Umang Bhatt**, Brenden Lake, Thomas Griffiths      
<span style="color:SlateBlue">Comparing Abstraction in Humans and Large Language Models Using Multimodal Serial Reproduction</span>      
*46th Annual Conference of the Cognitive Science Society (CogSci), 2024.*      
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2402.03618)           

1. Valerie Chen\*, **Umang Bhatt**\*, Hoda Heidari, Adrian Weller, Ameet Talwalkar      
<span style="color:SlateBlue">Perspectives on Incorporating Expert Feedback into Model Updates</span>      
*Patterns, 2023.*      
[<button type="button" class="btn btn-info">Paper</button>](https://www.sciencedirect.com/science/article/pii/S2666389923001319)   

1. Isa Inuwa-Dutse, Alice Toniolo, Adrian Weller, **Umang Bhatt**      
<span style="color:SlateBlue">Algorithmic Loafing and Mitigation Strategies in Human-AI Teams</span>      
*Computers in Human Behavior: Artificial Humans, 2023.*      
[<button type="button" class="btn btn-info">Paper</button>](https://www.sciencedirect.com/science/article/pii/S2949882123000245) 

1. Matthew Barker, Katherine Collins, Krishnamurthy Dvijotham, Adrian Weller, **Umang Bhatt**      
<span style="color:SlateBlue">Selective Concept Models: Permitting Stakeholder Customisation at Test-Time</span>      
*AAAI Conference on Human Computation and Crowdsourcing (HCOMP), 2023.*          
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2306.08424)           

1. Matthew Barker, Emma Kallina, Dhananjay Ashok, Katherine Collins, Ashley Casovan, Adrian Weller, Ameet Talwalkar, Valerie Chen, **Umang Bhatt**      
<span style="color:SlateBlue">FeedbackLogs: Recording and Incorporating Stakeholder Feedback into Machine Learning Pipeline</span>      
*ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization (EAAMO), 2023.*          
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2307.15475)
[<button type="button" class="btn btn-danger">Code</button>](https://github.com/barkermrl/feedback-log)
[<button type="button" class="btn">Press</button>](https://montrealethics.ai/feedbacklogs-recording-and-incorporating-stakeholder-feedback-into-machine-learning-pipelines/)               

1. Alan Chan, Rebecca Salganik, Alva Markelius, Chris Pang, Nitarshan Rajkumar, Dmitrii Krasheninnikov, Lauro Langosco, Zhonghao He, Yawen Duan, Micah Carroll, Michelle Lin, Alex Mayhew, Katherine Collins, Maryam Molamohammadi, John Burden, Wanru Zhao, Shalaleh Rismani, Konstantinos Voudouris, **Umang Bhatt**, Adrian Weller, David Krueger, Tegan Maharaj              
<span style="color:SlateBlue">Harms from Increasingly Agentic Algorithmic Systems</span>      
*ACM Conference on Fairness, Accountability, and Transparency (FAccT), 2023.*              
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2302.10329)    

1. Katherine Collins, Matthew Barker, Mateo Espinosa Zarlenga, Naveen Raman, **Umang Bhatt**, Mateja Jamnik, Ilia Sucholutsky, Adrian Weller, Krishnamurthy Dvijotham      
<span style="color:SlateBlue">Human Uncertainty in Concept-Based AI Systems</span>      
*AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES), 2023.*              
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2303.12872)
[<button type="button" class="btn">Press</button>](https://www.cam.ac.uk/research/news/how-sure-is-sure-incorporating-human-error-into-machine-learning)            

1. Zeju Qiu, Weiyang Liu, Tim Xiao, Zhen Liu, Yucen Luo, **Umang Bhatt**, Adrian Weller, Bernhard Scholkopf       
<span style="color:SlateBlue">Iterative Teaching by Data Hallucination</span>      
*International Conference on Artificial Intelligence and Statistics (AISTATS), 2023.*                
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2210.17467)    

1. Javier Abad Martinez, **Umang Bhatt**, Adrian Weller, Giovanni Cherubin       
<span style="color:SlateBlue">Approximating Full Conformal Prediction at Scale via Influence Functions</span>      
*AAAI Conference on Artificial Intelligence (AAAI), 2023.*                
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2202.01315)    

1. Mateo Zarlenga, Pietro Barbiero, Zohreh Shams, Dmitry Kazhdan, **Umang Bhatt**, Adrian Weller, Mateja Jamnik       
<span style="color:SlateBlue">Towards Robust Metrics for Concept Representation Evaluation</span>      
*AAAI Conference on Artificial Intelligence (AAAI), 2023.*                
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2301.10367)    

1. Katherine Collins, **Umang Bhatt**, Weiyang Liu, Vihari Piratla, Ilia Sucholutsky, Bradley Love, Adrian Weller      
<span style="color:SlateBlue">Human-in-the-Loop Mixup</span>      
*Conference on Uncertainty in Artificial Intelligence (UAI), 2023.* **(Oral)**             
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2211.01202)        

1. Ilia Sucholutsky, Ruairidh Battleday, Katherine Collins, Raja Marjieh, Joshua Peterson, Pulkit Singh, **Umang Bhatt**, Nori Jacoby, Adrian Weller, Thomas Griffiths            
<span style="color:SlateBlue">On the Informativeness of Supervision Signals</span>      
*Conference on Uncertainty in Artificial Intelligence (UAI), 2023.*              
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2211.01407)        

1. John Zerilli, **Umang Bhatt**, Adrian Weller      
<span style="color:SlateBlue">How Transparency Modulates Trust in Artificial Intelligence</span>      
*Patterns, 2022.*             
[<button type="button" class="btn btn-info">Paper</button>](https://www.sciencedirect.com/science/article/pii/S2666389922000289)     

1. Yuxin Xiao, Paul Pu Liang, **Umang Bhatt**,  Willie Neiswanger, Ruslan Salakhutdinov, Louis-Philippe Morency   
<span style="color:SlateBlue">Uncertainty Quantification with Pre-trained Language Models: A Large-Scale Empirical Analysis</span>      
*Findings of the Association for Computational Linguistics (EMNLP), 2022.*          
[<button type="button" class="btn btn-info">Paper</button>](https://aclanthology.org/2022.findings-emnlp.538/)
[<button type="button" class="btn btn-danger">Code</button>](https://github.com/xiaoyuxin1002/UQ-PLM)     

1. Katherine Collins\*, **Umang Bhatt**\*, Adrian Weller      
<span style="color:SlateBlue">Eliciting and Learning with Soft Labels from Every Annotator</span>      
*AAAI Conference on Human Computation and Crowdsourcing (HCOMP), 2022.*          
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2207.00810)
[<button type="button" class="btn btn-danger">Code</button>](https://github.com/cambridge-mlg/cifar-10s/)        

1. Varun Babbar, **Umang Bhatt**, Adrian Weller      
<span style="color:SlateBlue">On the Utility of Prediction Sets in Human-AI Teams</span>      
*International Joint Conference on Artificial Intelligence (IJCAI), 2022.* **(Oral)**       
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2205.01411)   

1. Dan Ley, **Umang Bhatt**, Adrian Weller      
<span style="color:SlateBlue">Diverse and Amortised Counterfactual Explanations for Uncertainty Estimates</span>      
*AAAI Conference on Artificial Intelligence (AAAI), 2022.*     
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2112.02646)       

1. Julius von Kugelgen, Amir-Hossein Karimi, **Umang Bhatt**, Isabel Valera, Adrian Weller, Bernhard Scholkopf                
<span style="color:SlateBlue">On the Fairness of Causal Algorithmic Recourse</span>      
*AAAI Conference on Artificial Intelligence (AAAI), 2022.* **(Oral)**       
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2010.06529)   

1. **Umang Bhatt**, Javier Antoran, Yunfeng Zhang, Q. Vera Liao, Prasanna Sattigeri, Riccardo Fogliato, Gabrielle Melancon, Ranganath Krishnan, Jason Stanley,  Omesh Tickoo, Lama Nachman, Rumi Chunara, Madhulika Srikumar, Adrian Weller, Alice Xiang     
<span style="color:SlateBlue">Uncertainty as a Form of Transparency: Measuring, Communicating, and Using Uncertainty</span>   
*AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES) 2021.*   
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2011.07586)    

1. Javier Antoran, **Umang Bhatt**, Tameem Adel, Adrian Weller, Jose Miguel Hernandez-Lobato            
<span style="color:SlateBlue">Getting a CLUE: A Method for Explaining Uncertainty Estimates</span>      
*International Conference on Learning Representations (ICLR), 2021.* **(Oral)**     
[<button type="button" class="btn btn-info">Paper</button>](https://openreview.net/pdf?id=XSLF1XFq5h)
[<button type="button" class="btn btn-danger">Code</button>](https://github.com/cambridge-mlg/CLUE)       

1. Matt Chapman-Rounds,  **Umang Bhatt**,  Erik Pazos, Marc-Andre Schulz, Konstantinos Georgatzis    
<span style="color:SlateBlue">FIMAP: Feature Importance by Minimal Adversarial Perturbation</span>     
*AAAI Conference on Artificial Intelligence (AAAI), 2021.*     
[<button type="button" class="btn btn-info">Paper</button>](https://ojs.aaai.org/index.php/AAAI/article/view/17362)    

1. **Umang Bhatt**, Adrian Weller, Jos&eacute; M. F. Moura    
<span style="color:SlateBlue">Evaluating and Aggregating Feature-based Model Explanations</span>   
*International Joint Conference on Artificial Intelligence (IJCAI), 2020.*   
[<button type="button" class="btn btn-info">Paper</button>](https://www.ijcai.org/Proceedings/2020/0417) 
[<button type="button" class="btn btn-success">Poster</button>](/reports/ijcai20_poster.pdf){:target="_blank"} 
[<button type="button" class="btn btn-warning">Slides</button>](/reports/ijcai20_slides.pdf){:target="_blank"} 
[<button type="button" class="btn btn-vid">Video</button>](https://videos.ijcai20.org/26669/index.html)     

1. **Umang Bhatt**, Alice Xiang, Shubham Sharma, Adrian Weller, Ankur Taly, Yunhan Jia, Joydeep Ghosh, Ruchir Puri, Jos&eacute; M. F. Moura, Peter Eckersley  
<span style="color:SlateBlue">Explainable Machine Learning in Deployment</span>   
*ACM Conference on Fairness, Accountability, and Transparency (FAccT), 2020.*   
[<button type="button" class="btn btn-info">Paper</button>](https://dl.acm.org/doi/abs/10.1145/3351095.3375624)
[<button type="button" class="btn btn-success">Poster</button>](/reports/hcml.pdf){:target="_blank"} 
[<button type="button" class="btn">Blog</button>](https://www.partnershiponai.org/xai-in-practice/)
[<button type="button" class="btn btn-warning">Slides</button>](/reports/fat_slides.pdf){:target="_blank"}
[<button type="button" class="btn btn-vid">Video</button>](https://www.youtube.com/watch?v=Hofl4uwxtPA)     

1. Botty Dimanov, **Umang Bhatt**, Mateja Jamnik, Adrian Weller   
<span style="color:SlateBlue">You shouldn't trust me: Learning models which conceal unfairness from multiple explanation methods</span>    
*European Conference on Artificial Intelligence (ECAI), 2020.*  
[<button type="button" class="btn btn-info">Paper</button>](http://ecai2020.eu/papers/72_paper.pdf)
[<button type="button" class="btn">Press</button>](https://spectrum.ieee.org/computing/software/its-too-easy-to-hide-bias-in-deeplearning-systems)       

1. Brian Davis\*, **Umang Bhatt**\*, Kartikeya Bhardwaj\*, Radu Marculescu, Jos&eacute; M. F. Moura   
<span style="color:SlateBlue">On Network Science and Mutual Information for Explaining Deep Neural Networks</span>    
*IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2020.*    
[<button type="button" class="btn btn-info">Paper</button>](https://ieeexplore.ieee.org/document/9053078)          

1. Aaron Roth, Samantha Reig, **Umang Bhatt**, Jonathan Shulgach, Tamara Amin, Afsaneh Doryab, Fei Fang, Manuela Veloso   
<span style="color:SlateBlue">A Robot’s Expressive Language Affects Human Strategy and Perceptions in a Competitive Game</span>    
*IEEE International Conference on Robot and Human Interactive Communication (ROMAN), 2019.*       
[<button type="button" class="btn btn-info">Paper</button>](https://ieeexplore.ieee.org/document/8956412)
[<button type="button" class="btn">Blog</button>](https://www.cmu.edu/news/stories/archives/2019/november/robot-trash-talk.html)    

1. **Umang Bhatt**\*, Edgar Xi\*, Shouvik Mani\*, Zico Kolter   
<span style="color:SlateBlue">Intelligent Pothole Detection and Road Condition Assessment</span>   
*Bloomberg Data for Good Exchange (D4GX), 2017.*    
*Talk at UChicago Data Science for Social Good (DSSG), 2017.*    
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/1710.02595)
[<button type="button" class="btn btn-danger">Code</button>](https://github.com/shouvikmani/Intelligent-Pothole-Detection)
[<button type="button" class="btn">Blog</button>](https://medium.com/@percepsense/intelligent-pothole-detection-879ef635dd38)
[<button type="button" class="btn btn-vid">Video</button>](https://www.youtube.com/watch?v=w6RMC_io--U&feature=emb_logo)     

-----

### Theses    

1. **Umang Bhatt**          
<span style="color:SlateBlue">Trustworthy Machine Learning: From Algorithmic Transparency to Decision Support</span>      
*Universty of Cambridge, 2024.*         
[<button type="button" class="btn btn-info">Paper</button>](https://www.repository.cam.ac.uk/items/065ba398-4026-43f1-b925-641fb8d6dd82)   

-----

### Book Chapters (Refereed and Archived)    

1. **Umang Bhatt**, Zohreh Shams      
<span style="color:SlateBlue">Trust in Artificial Intelligence: Clinicians Are Essential</span>      
*Healthcare Information Technology for Cardiovascular Medicine, 2021.*         
[<button type="button" class="btn btn-info">Paper</button>](https://link.springer.com/chapter/10.1007/978-3-030-81030-6_10)   

-----

### Workshop Publications (Refereed) -- Not Updated Frequently

1. Ana Lucic, Sheeraz Ahmad, Amanda Furtado Brinhosa, Vera Liao, Himani Agrawal, **Umang Bhatt**, Krishnaram Kenthapadi, Alice Xiang, Maarten de Rijke, Nicholas Drabowski      
<span style="color:SlateBlue">Towards the Use of Saliency Maps for Explaining Low-Quality Electrocardiograms to End Users</span>      
*ICML Workshop on Interpretable ML in Healthcare, 2022.*      
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2207.02726)  

1. Valerie Chen\*, **Umang Bhatt**\*, Hoda Heidari, Adrian Weller, Ameet Talwalkar      
<span style="color:SlateBlue">Perspectives on Incorporating Expert Feedback into Model Updates</span>      
*ICML Workshop on Updatable Machine Learning, 2022.*      
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2205.06905)   

1. **Umang Bhatt**, Adrian Weller, Giovanni Cherubin      
<span style="color:SlateBlue">Fast Conformal Classification using Influence Functions</span>      
*10th Symposium on Conformal and Probabilistic Prediction with Applications (COPA), 2021.*         
[<button type="button" class="btn btn-info">Paper</button>](https://proceedings.mlr.press/v152/bhatt21a.html)       

1. Dan Ley, **Umang Bhatt**, Adrian Weller      
<span style="color:SlateBlue">Diverse and Amortised Counterfactual Explanations for Uncertainty Estimates</span>      
*ICML Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI, 2021.*             
[<button type="button" class="btn btn-info">Paper</button>](https://drive.google.com/file/d/1wd7KPSPTqzVQqqb7IgS0XgwOnANzgsX7)     

1. Andrei Margeloiu\*, Matthew Ashman\*, **Umang Bhatt**\*, Yanzhi Chen, Mateja Jamnik, Adrian Weller      
<span style="color:SlateBlue">Do Concept Bottleneck Models Learn As Intended?</span>      
*ICLR Workshop on Responsible AI, 2021.*      
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2105.04289)          

1. Dan Ley, **Umang Bhatt**, Adrian Weller      
<span style="color:SlateBlue">δ-CLUE: Diverse Sets of Explanations for Uncertainty Estimates</span>      
*ICLR Workshop on Security and Safety in Machine Learning Systems, 2021.*         
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2104.06323)     

1. Ana Lucic, Madhulika Srikumar, **Umang Bhatt**, Alice Xiang, Ankur Taly, Q. Vera Liao, Maarten de Rijke    
<span style="color:SlateBlue">A Multistakeholder Approach Towards Evaluating AI Transparency Mechanisms</span>      
*CHI Workshop on Operationalizing Human-centered Perspectives in Explainable AI, 2021.*          
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2103.14976)    

1. Torgyn Shaikhina\*, **Umang Bhatt**\*, Roxanne Zhang, Konstantinos Georgatzis, Alice Xiang,  Adrian Weller   
<span style="color:SlateBlue">Effects of Uncertainty on the Quality of Feature Importance Estimates</span>      
*AAAI Workshop on Explainable Agency in Artificial Intelligence, 2021.*      
[<button type="button" class="btn btn-info">Paper</button>](/reports/AAAI_XAI_QB.pdf){:target="_blank"}   

1. Julius von Kugelgen, **Umang Bhatt**, Amir-Hossein Karimi, Isabel Valera, Adrian Weller, Bernhard Scholkopf                
<span style="color:SlateBlue">On the Fairness of Causal Algorithmic Recourse</span>      
*NeurIPS Workshop on Algorithmic Fairness through the Lens of Causality and Interpretability, 2020.*     
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2010.06529)    

1. **Umang Bhatt**, McKane Andrus, Adrian Weller, Alice Xiang                
<span style="color:SlateBlue">Machine Learning Explainability for External Stakeholders</span>      
*ICML Workshop on Extending Explainable AI: Beyond Deep Models and Classifiers, 2020.*   
*ICML Workshop on Human Interpretability, 2020.* **(Spotlight)**    
*IJCAI Workshop on Explainable AI, 2020.*     
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2007.05408)
[<button type="button" class="btn">Blog</button>](https://www.partnershiponai.org/multistakeholder-explainableml/)     

1. Javier Antoran, **Umang Bhatt**, Jose Miguel Hernandez-Lobato, Adrian Weller, Tameem Adel                
<span style="color:SlateBlue">Getting a CLUE: A Method for Explaining Uncertainty Estimates</span>      
*ICLR Workshop on Machine Learning in Real Life (ML-IRL), 2020.* **(Oral)**  
[<button type="button" class="btn btn-info">Paper</button>](/reports/ML_IRL_20_CLUE.pdf){:target="_blank"}          

1. **Umang Bhatt**, Adrian Weller, Muhammad Bilal Zafar, Krishna Gummadi                 
<span style="color:SlateBlue">Counterfactual Accuracies of Alternative Models</span>         
*ICLR Workshop on Machine Learning in Real Life (ML-IRL), 2020.*   
[<button type="button" class="btn btn-info">Paper</button>](/reports/ML_IRL_20_CFA.pdf){:target="_blank"}
[<button type="button" class="btn btn-warning">Slides</button>](/reports/cfa_iclr.pdf){:target="_blank"}     

1. Botty Dimanov, **Umang Bhatt**, Mateja Jamnik, Adrian Weller   
<span style="color:SlateBlue">Models can be learned to conceal unfairness from explanation methods</span>   
*AAAI Workshop on Safe AI, 2020.* **(Oral)**     
[<button type="button" class="btn btn-info">Paper</button>](/reports/ecai.pdf){:target="_blank"}   

1. **Umang Bhatt**, Alice Xiang, Shubham Sharma, Adrian Weller, Ankur Taly, Yunhan Jia, Joydeep Ghosh, Ruchir Puri, Jos&eacute; M. F. Moura, Peter Eckersley  
<span style="color:SlateBlue">Explainable Machine Learning in Deployment</span>    
*NeurIPS Workshop on Human-Centric Machine Learning (HCML), 2019.*    
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/1909.06342)
[<button type="button" class="btn btn-success">Poster</button>](/reports/hcml.pdf){:target="_blank"}   

1. **Umang Bhatt**, Brian Davis, Jos&eacute; M. F. Moura     
<span style="color:SlateBlue">Diagnostic Model Explanations: A Medical Narrative</span>    
*AAAI Spring Symposium on Interpretable AI for Well-being, 2019.*    
**Best Paper Award**    
[<button type="button" class="btn btn-info">Paper</button>](/reports/iaw.pdf){:target="_blank"}    

1. Brian Davis\*, **Umang Bhatt**\*, Kartikeya Bhardwaj\*, Radu Marculescu, Jos&eacute; M. F. Moura        
<span style="color:SlateBlue">NIF: A Framework for Quantifying Neural Information Flow in Deep Networks</span>      
*AAAI Workshop on Network Interpretability for Deep Learning, 2019.*     
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/1901.08557)
[<button type="button" class="btn btn-success">Poster</button>](/reports/nif.pdf){:target="_blank"}  

1. **Umang Bhatt**, Pradeep Ravikumar, Jos&eacute; M. F. Moura   
<span style="color:SlateBlue">Towards Aggregating Weighted Feature Attributions</span>    
*AAAI Workshop on Network Interpretability for Deep Learning, 2019.*    
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/1901.10040)
[<button type="button" class="btn btn-success">Poster</button>](/reports/ava_wrkshp.pdf){:target="_blank"} 

1. **Umang Bhatt**, Pradeep Ravikumar, Jos&eacute; M. F. Moura   
<span style="color:SlateBlue">Building Human-Machine Trust via Interpretability</span>    
*AAAI Conference on Artificial Intelligence (AAAI), 2019.* (Student Abstract)       
[<button type="button" class="btn btn-info">Paper</button>](https://www.aaai.org/ojs/index.php/AAAI/article/view/5096)
[<button type="button" class="btn btn-success">Poster</button>](/reports/studentposter.pdf){:target="_blank"} 

1. Aaron Roth\*, **Umang Bhatt**\*, Tamara Amin\*, Afsaneh Doryab, Fei Fang, Manuela Veloso   
<span style="color:SlateBlue">The Impact of Humanoid Affect Expression on Human Behavior in Game-Theoretic Setting</span>      
*IJCAI Workshop on Humanizing Artificial Intelligence, 2018.* **(Oral)**   
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/1806.03671) 

1. **Umang Bhatt**  
<span style="color:SlateBlue">Maintaining the Humanity of Our Models</span>    
*AAAI Spring Symposium on AI and Society: Ethics, Safety and Trustworthiness in Intelligent Agents, 2018.*     
[<button type="button" class="btn btn-info">Paper</button>](https://www.aaai.org/ocs/index.php/SSS/SSS18/paper/view/17478/15369)

